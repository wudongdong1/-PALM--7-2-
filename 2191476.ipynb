{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "用paddle.vision.models下的restnet50网络。把图片都裁剪成867X1155，主要为了减小图片尺寸，去掉周边对无用的图片信息。采用INNER_AREA插值进行resize，减小失真。momentem,0.9,学习率0.0001，是多次实验之后的选择。800张图片都用来训练，patch=10,训练75轮后提交后AUC：0.99962\n",
    "忘记保留checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting xlwt\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 10.6MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: xlwt\n",
      "Successfully installed xlwt-1.3.0\n"
     ]
    }
   ],
   "source": [
    "#安装xlwt，用于生成xls表格，保存预测结果\r\n",
    "!pip install xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'work'\n",
      "/home/aistudio/work\n"
     ]
    }
   ],
   "source": [
    "#切换到work目录下运行\n",
    "%cd work\n",
    "import paddle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddle.vision.models import resnet101,resnet50\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "from paddle.optimizer import Momentum\n",
    "from paddle.regularizer import L2Decay\n",
    "from paddle.nn import CrossEntropyLoss\n",
    "from paddle.metric import Accuracy, Auc\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.vision.transforms import RandomHorizontalFlip,RandomVerticalFlip\n",
    "from PIL import ImageEnhance,Image\n",
    "import random\n",
    "import xlwt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#用于图像裁剪，裁剪成H X W 是867X1155的图片\n",
    "def image_crop(img):\n",
    "    H=img.shape[0]\n",
    "    img_crop=img[int(H*0.2):int(H*0.8),0:int(H*0.8)]\n",
    "    img_crop_H=img_crop.shape[0]\n",
    "    img_crop_W=img_crop.shape[1]\n",
    "    return img_crop,img_crop_H,img_crop_W\n",
    "\n",
    "\n",
    "\n",
    "#获取图片信息，包括图片名字和标签，以列表的形式，列表里面包含一个个元组，格式是（图片名字，标签）\n",
    "def get_annotations(mode1=None):\n",
    "    df = pd.read_excel('Train/Classification.xlsx')\n",
    "    images = df.loc[:,'imgName'].values\n",
    "    labels = df.loc[:,'Label'].values\n",
    "    anno_lst=[]\n",
    "    test=[]\n",
    "    for image,label in zip(images,labels):\n",
    "        anno_lst.append((image,label))\n",
    "    if mode1 =='train':\n",
    "        result=anno_lst[0:800]       \n",
    "\n",
    "    elif mode1 =='valid':\n",
    "        result=anno_lst[700:800]\n",
    "    elif mode1 =='test':\n",
    "        images_name=os.listdir('PALM-Testing400-Images')\n",
    "        for image in images_name:\n",
    "            test.append((image,1000))\n",
    "        return test\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#获取图象数据，返回的值分别是图像数组，标签，图片名字\n",
    "def get_img_data(datadir,record, size, mode2=None):\n",
    "    \n",
    "    img=cv2.imread(datadir+'/'+record[0])\n",
    "    img,H,W=image_crop(img)\n",
    "    if H!=867:\n",
    "        img=cv2.resize(img,size,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    mean = np.array(mean).reshape((1, 1, -1))\n",
    "    std = np.array(std).reshape((1, 1, -1))\n",
    "    img = (img / 255.0 - mean) / std\n",
    "    \n",
    "    img=np.transpose(img,(2,0,1)).astype('float32')\n",
    "    \n",
    "    \n",
    "    if mode2=='train' or 'valid':\n",
    "        record1=np.array([record[1]])\n",
    "        record1=record1.astype('int64')\n",
    "    return img,record1,record[0]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class TrainDataset(paddle.io.Dataset):\n",
    "    def  __init__(self,mode='train'):\n",
    "        if mode=='train' or mode=='valid':\n",
    "            self.datadir='Train/fundus_image'\n",
    "        elif mode=='test':\n",
    "            self.datadir='PALM-Testing400-Images'\n",
    "    \n",
    "        self.mode=mode\n",
    "        self.records = get_annotations(mode1=mode)\n",
    "        \n",
    "        self.img_size = (1155, 867)  #get_img_size(mode)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        # print(\"print: \", record)\n",
    "        try:\n",
    "            \n",
    "            img, label,img_name = get_img_data(self.datadir,record, size=self.img_size,mode2=self.mode)\n",
    "                                \n",
    "        except:\n",
    "            print('图片出现错误',record)\n",
    "\n",
    "        return img, label,img_name\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "\n",
    "\n",
    "#定义模型主体\n",
    "class resnet_model(paddle.nn.Layer):\n",
    "    def __init__(self,class_num):\n",
    "        super(resnet_model,self).__init__()\n",
    "        self.model=resnet50(pretrained=True)\n",
    "        self.fc=Linear(1000,class_num)\n",
    "    def forward(self,x):\n",
    "        out=self.model(x)\n",
    "        out1=self.fc(out)\n",
    "        return out1\n",
    "\n",
    "\n",
    "\n",
    "#训练函数\n",
    "def train(model):\n",
    "    \n",
    "    opt = paddle.optimizer.Momentum(learning_rate=0.0001, momentum=0.9, parameters=model.parameters(), weight_decay=0.001)\n",
    "    \n",
    "    train_dataset=TrainDataset(mode='train')\n",
    "    train_loader=paddle.io.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0, drop_last=True)\n",
    "    valid_dataset=TrainDataset(mode='valid')\n",
    "    valid_loader=paddle.io.DataLoader(valid_dataset, batch_size=10, shuffle=True, num_workers=0, drop_last=True)\n",
    "    epoches=76\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "\n",
    "        for batch_id,batch in enumerate(train_loader()):\n",
    "            x=batch[0]\n",
    "            label=batch[1]\n",
    "            out=model(x)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = F.cross_entropy(out,label)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            if batch_id % 5 == 0:\n",
    "                print(\"train:epoch: {}, batch_id: {}, loss is: {:.5f}\".format(epoch, batch_id, loss.numpy()[0]))\n",
    "            # 反向传播，更新权重，清除梯度\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "        paddle.save(model.state_dict(), 'output/epoch'+str(epoch)+'.pdparams')\n",
    "        paddle.save(opt.state_dict(), 'output/epoch'+str(epoch)+'.pdopt')\n",
    "\n",
    "        \n",
    "'''\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        \n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            img=data[0]\n",
    "            label1=data[1]\n",
    "           \n",
    "            # 运行模型前向计算，得到预测值\n",
    "            out1 = model(img)\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\n",
    "            \n",
    "            pred = F.softmax(out1)\n",
    "            loss = F.cross_entropy(out1, label1)\n",
    "           \n",
    "            \n",
    "            acc = paddle.metric.accuracy(pred, label1)\n",
    "\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {:.5f}/{:.5f}\".format(acc.numpy()[0], loss.numpy()[0]))\n",
    "        \n",
    "        model.train()\n",
    "\n",
    " '''       \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#预测函数\n",
    "def predict(model):\n",
    "   \n",
    "    #预测时，请加载训练好的用来预测的xxx.pdparams\n",
    "    model_pararams=paddle.load('output/75_99962.pdparams')\n",
    "    \n",
    "\n",
    "    model.load_dict(model_pararams)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset=TrainDataset(mode='test')\n",
    "    test_loader=paddle.io.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    \n",
    "    m = Auc()\n",
    "    \n",
    "    num=0\n",
    "    nums=len(test_loader())\n",
    "    sum0=[]\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    book = xlwt.Workbook() #创建Excel\n",
    "    sheet = book.add_sheet('sheet1')\n",
    "    sheet.write(0,0,'FileName')\n",
    "    sheet.write(0,1,'PM Risk')\n",
    "\n",
    "    for batch_id,batch in enumerate(test_loader()):\n",
    "        \n",
    "        x=batch[0]\n",
    "        \n",
    "        out=model(x)\n",
    "        \n",
    "        result=F.softmax(out)\n",
    "        result=result.numpy()\n",
    "        preds.append(list(result[0]))\n",
    "        #labels.append(batch[1].numpy()[0])\n",
    "        #if np.argmax(result[0])==batch[1].numpy()[0][0]:\n",
    "        #    num=num+1\n",
    "        #if batch[1].numpy()[0][0]==1:\n",
    "        #    sum0.append(result[0][1])\n",
    "        #elif batch[1].numpy()[0][0]==0:\n",
    "        #    sum0.append(result[0][0])\n",
    "        sheet.write(batch_id+1,0,batch[2])\n",
    "        sheet.write(batch_id+1,1,float(result[0][1]))\n",
    "                \n",
    "        book.save('Classification_Results.xls')\n",
    "        #print(batch[2],classes[np.argmax(result[0])],result[0].max())\n",
    "    #print('评价指标1，valid上的准确率：',num,nums,num/nums)\n",
    "    #print('评价指标2,valid上的准确率:',sum(sum0)/len(sum0))\n",
    "    #preds=np.array(preds)\n",
    "    #labels=np.array(labels)\n",
    "    \n",
    "    #m.update(preds=preds, labels=labels)\n",
    "    #res = m.accumulate()\n",
    "    #print('Auc:',res)\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "model1 = resnet_model(2)\n",
    "\n",
    "\n",
    "#启动训练，预测时请注释\n",
    "#train(model1)\n",
    "\n",
    "#启动预测，训练时请注释\n",
    "predict(model1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
